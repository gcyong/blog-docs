# 문자 부호화(Character encoding)

## 1. 문자(Character)
알파벳이나 자연어에서 쓰이는 음절 형태와 같이 문자소(grapheme), 문자소 비슷한 단위(grapheme-like unit), 또는 기호 정보의 단위이다. 가령, 문자는 글자(letters), 숫자(numerical digits), 점(.)이나 하이픈(-), 공백 등을 포함한다. 컴퓨터에서의 문자는 제어 문자(control characters) 또한 포함하는데, 이건 특정 자연어에서 기호로 나타나지 않는 것들이나 하나 이상의 언어에서 텍스트를 처리하기 위해 사용되는 몇 비트의 정보이다. 예를 들어, 프린터 명령이나 테스트를 보여주거나 처리하는 명령어 뿐만 아니라, 제어 문자에는 캐리지 리턴(carriage reeturn, 다음 줄로 커서를 내리는 지시 문자), 탭(tab)이 포함되어 있다.

## 2. 문자열(String)
문자를 일련으로 결합한 것이다.

## 3. 문자 부호화(Character encoding)
문자 부호화는 어떤 종류의 부호화 시스템(encoding system)에 의해 문자의 레퍼토리를 표현하는 데 사용됨. 추상적인 수준과 문맥(context)에 의하면 코드 포인트(code points)와 부호화 결과 도출되는 코드 공간은 비트 열(bit patterns), 옥텟(octets), 자연수(natural numbers), 전파 등으로 간주할 수 있다.

문자 부호화는 계산(computation), 데이터 저장(data storage), 그리고 테스트 기반의 데이터의 전달에 사용된다. 문자 집합(character set), 문자 대응(character map), 코드 집합(codeset)이 관련되어 있는데, 각각이 별개로 존재하여 관련이 있는게 아니라(not identical) 관점(terms)에서 차이가 있을 뿐이다.

문자는 인코딩을 통해 부호화 되며, 부호화 된 값(code)을 다시 복호화 했을 때 나오는 부호는 (당연히) 원래 문자나 기호를 뜻하게 되는데 이를 문자 코드(character code)라고 한다.

### 3.1 ASCII
미국 정보교환 표준부호(American Standard Code for Information Interchange)의 약자로 7비트 영문 알파벳의 인코딩이다.

![https://upload.wikimedia.org/wikipedia/commons/c/cf/USASCII_code_chart.png](https://upload.wikimedia.org/wikipedia/commons/c/cf/USASCII_code_chart.png)

필요한 제어 문자(라인 피드(line feed), 캐리지 리턴(carriage return) 등)와 표시 문자(직관적인 문자; 알파벳이나 숫자 등)를 7비트에 표시하므로 최대 128개 저장할 수 있는 표준이다. 8비트가 아닌 이유는 다양하겠지만, 대표적으로 ASCII 표준이 제정되던 1960년대에는 컴퓨터 하드웨어가 정의하고 있는 처리 단위가 8비트만 있던건 아니었기 때문이다. 특히, 바이트(byte)의 의미가 현재는 8비트로 사실상 고정되어 있지만 엄밀히 말하면 비트 개수가 정해진 것은 아니다. 컴퓨터에 따라 7비트를 1바이트로 나타내도 되고, 9비트를 1바이트로 정의했을 때 얻는 이득이 크다면 그렇게 할 수도 있는 것이다. 다만, 상기했듯이 현재는 8비트를 1바이트로 나타내는 것이 일반적이며 이 규칙은 앞으로도 바뀌지는 않을 것이다. (정확히 8비트를 나타내는 단위는 옥텟(octet)이다.) 

한편, 8비트를 1바이트로 나타내는 컴퓨터에서는 ASCII를 나타내는 데 1비트가 남게 된다. 처음에는 이 부분을 패리티 비트(parity bit)로 사용했지만 시간이 지남에 따라 추가적인 문자(특히, 유럽을 위한 문자, 수학 기호, 선(line)을 나타내는 문자 등)가 요구되어 패리티 비트 대신 문자를 표현하기 위한 비트로 확장하기에 이르는데, 이를 extended ASCII라고 한다. 하지만, 이 규격은 일부 유럽 지역에서 사용한 일종의 아류 규격쯤 되는 것들이고 대부분의 문자가 유니코드로 표현함에 따라 여덟번 째 비트는 0으로 표현하도록 하는 것이 일반적이다.

유니코드 중의 UTF-8 방식에서 U+0000부터 U+007F (첫 7비트)는 ASCII 코드와 100% 일치하면서 유니코드는 기존의 ASCII를 그대로 안고갈 수 있게 되었다.

## 4. 한글 인코딩 방식
문자 인코딩의 표준으로 ASCII가 제정되고 상당히 널리 쓰이고 있었지만 영문 알파벳과 숫자, 그리고 몇 개의 특수문자를 제외한 문자 체계는 표시할 수 없다는 단점이 존재했다. 그나마 유럽은 ASCII에서 약간의 수정만 있으면 유럽 문자를 표시할 수 있었고 실제로 그렇게하여 [ISO/IEC 8859-n](https://en.wikipedia.org/wiki/ISO/IEC_8859) 표준이 마련되었지만, 아시아 (중에서 특히 문자가 많기로 소문난 [CJK(Chinese-Japanese-Korean)](https://en.wikipedia.org/wiki/CJK_characters))는 자체적인 표준안을 만들어야 했다.

그 중에서 우리의 관심사인 한글의 인코딩 방식을 알아보자. 한글 인코딩 방식은 부호화된 문자를 조립해야 하는지의 여부에 따라 조합형(각 파자에 대해 코드가 대응되어 있고, 파자 코드를 조합하여 글자를 구성하는 방식)과 완성형(이미 조립된 문자가 하나의 코드로 대응되는 경우)으로 나뉘는데, 각 형태에 따라서도 여러 표준안이 존재한다. 심지어 북한의 한글 코드까지 고려한다면 그 복잡성을 더욱 늘어날 것이나 북한은 아직 닿을 수 없는 곳에 있기 때문에 대한민국에서 사용하는 한글만을 다루도록 한다.

### 4.1 조합형
한글 제자원리인 자모 조합 방식을 그대로 옮긴 것이다. 가령, '각' 이라는 글자에 대해 'ㄱ' 코드와 'ㅏ' 코드와 'ㄱ' 코드를 차례로 조합하면 '각'에 해당하는 코드가 만들어진다. 장점으로는 조합을 통해 글자를 만들기 때문에 몇 개 되지 않은 자모만 있으면 한글로 표현할 수 있는 모든 글자를 부호화 할 수 있다는 점이나, 단점으로는 완성형에 비해 차지하는 용량이 크다는 점이 있다. 사실, 한글에서 주로 사용하는 글자는 3천~5천(고문헌 포함) 자 정도이며, '괋'이나 '괿' 같은 글자는 잘 사용하지 않는다. 따라서 이런 글자들까지 표현할 필요는 생각보다 적으며, 사용 빈도가 높은 글자만 모아두면 완성형 글자가 더 유리한 셈이다.

#### 4.1.1 n바이트 조합형
낱자(자모) 하나 당 1바이트 씩 할당하는 방식이다. 글자를 낱자로 분리하여 각 낱자당 대응되는 코드로 입력하면 되는 간단한 방식이다. 별도의 알고리즘이 없어도 표현할 수 있을정도로 단순하며 직관적이나 글자별로 차지하는 코드의 길이가 달라진다. 가령, '가'는 'ㄱ'과 'ㅏ'를 저장해야 하므로 2바이트가 소모되지만 '괆'은 'ㄱ', 'ㅗ', 'ㅏ', 'ㄹ', 'ㅁ' 총 5바이트가 소모된다.

#### 4.1.2 3바이트 조합형
초성, 중성, 종성에 1바이트씩 할당한 방식이다. 만일 받침(종성)이 없는 글자인 경우에 대비하여 '채움 글자'를 따로 정의하여 채워 넣었다.

#### 4.1.3 2바이트 조합형
2바이트는 (통상적으로) 16비트인데, 16비트 중 MSB를 1로 설정하여 한글임을 표시하고, 15비트를 셋으로 나누어 각 5비트씩 초성, 중성, 종성을 표시한다. 단점으로는, 첫 비트가 0이면 ASCII 코드와 충돌하게 된다는 점(특히 extended ASCII와는 더욱 충돌 가능성이 높다. 그래서 과거 MS-DOS시절 installation 따위에서 박스 모양을 흉내내기 위해 선 문자(line character)를 많이 썼을 때 코드 페이지가 한글일 경우 '괋', '굃' 등의 괴랄한 문자가 출력된 것이다. 흔히 이를 '깨진 문자' 라고 표현하기도 했다.)과 회사 별로 규격이 달라(금성 조합형, 삼성 조합형, (삼보를 주축으로 하는) 상용조합형 등) 호환성이 낮앗다. 참고로 상용 조합형(KSSM)은 이후 1992년 KS X 1001-3 표준으로 지정된다.

조합형은 후술할 완성형에 비해 그 양이 적은데, 왜냐하면 Windows의 등장 이후 MS의 확장 완성형과 유니코드에서 완성형 인코딩 방식을 초기 완성형 방식에 글자를 더 넣어서 충분히 제공했기 때문이다. 그리고 'ㄱ'이나 'ㅏ'처럼 낱자로 처리하는 경우보다 '가'로 조립한 채 처리하는 양이 훨씬 많기 때문이다. 사실, 완벽한 조합형을 실현하기 위해서는 (초성) x (중성) x (종성) 의 3차원 배열로 모두 조합할 수 있어야 하나, 실제로 현대 한국어에서 사용되는 글자 수는 11,172자에 불과하며 나머지는 글자로 인정이 안되거나 옛한글이다. 즉, 조합형으로 구현하면 이론적으로 모든 글자를 표현할 수 있지만 실제로는 모든 글자를 표현할 필요가 없다는 것이다. 또한, English alphabet이나 유럽 문자 등 외국 문자와 같은 문자셋에서 다루려면 11,172자를 순서대로 나열해야 한다. 앞서 언급한 문자들은 정해진 알파벳을 순서대로 나열하여 단어를 구성하기 때문이다. 따라서 한글도 어차피 조립해서 나열해야 하기 때문에 글자를 직접 조립하는 방식을 점점 사용하지 않고 있다.

### 4.2 완성형
현재 산업 표준인 완성형 인코딩 방식은 조합할 수 있는 글자를 미리 만들어 대응되는 값을 만들고, 글자를 읽으면 그 값으로 인코딩 하는 방식이다. 표준 번호는 KS X 1001(KS C 5601)로, 1974년에 처음 제정되어 1987년에 제정된 표준을 흔히 사용한다.

한글 인코딩 방식이 과도기를 거치는 동안 조합형 방식에 비해 적을 수 있는 글자가 적어 많은 에피소드를 만들어 냈다. 하지만 MS-DOS 시절부터 꾸준히 MS가 완성형을 기본으로 한글을 제공 하였고, 이후 유니코드에 모든 현대 국어에서 사용하는 글자가 반영되면서 조합형 방식을 제치고 한글 인코딩의 표준으로 자리매김 했다.

#### 4.2.1 EUC-KR
확장 유닉스 코드(Extended Unix Code, EUC)는 ISO-2022 표준에 기반한 CJK(Chinese-Japanese-Korean)를 위한 8비트 문자 인코딩 방식으로, 특히 EUC-KR 인코딩 방식은 문자 집합인 KS X 1001 (KS C 5601)과 KS X 1003(0x5C에 ＼ 대신 ￦로 대체한 것만 빼면 ASCII와 동일)에 대한 인코딩 방식이다.

![https://upload.wikimedia.org/wikipedia/commons/5/5e/Euckr-map.png](https://upload.wikimedia.org/wikipedia/commons/5/5e/Euckr-map.png)

EUC-KR은 경우에 따라 1바이트(MSB가 0인 경우)일 수도 있고, 2바이트(각 바이트별로 MSB가 1인 경우)일 수도 있다. 위 그림이 그것을 보여준다.

##### 4.2.1.1 KS X 1001 (구 KS C 5601)
![https://upload.wikimedia.org/wikipedia/ko/f/fc/Ksx1001-map.png](https://upload.wikimedia.org/wikipedia/ko/f/fc/Ksx1001-map.png)

1974년 처음 제정된 이 규격은 처음 KS C 5601로 명명되었으나, 국가 표준(KS)의 정보 표준 분야(X)를 신설하면서 카테고리를 이동하게 되었다. 특히, KS X(정보) - 10(문자세트, 부호화, 자동인식) 부분 첫 규격이 바로 KS X 1001(정보 교환용 부호계(한글 및 한자))이다. 이 규격은 가로, 세로 길이가 각 94인 이차원 배열에 완성된 글자('가', '나', '다' 등)를 대응시키는 방법이다. 가로와 세로에 대해 각 1바이트씩 할당하므로 한 글자당 2바이트씩 차지한다. 따라서 가로와 세로의 곱, 그러니까 94의 제곱인 8,836개의 글자를 저장할 수 있다.

그런데, 간단하게 256의 제곱인 65,536개의 글자를 저장할 수 있는데 왜 애매한 숫자인 94를 지정했을까? 왜냐하면 ASCII를 확장하여 만들어진 규격이기 때문이다. ASCII는 상기했듯이 7비트를 사용하는 체계이므로 (패리티 비트를 사용하지 않으면) MSB는 무조건 0으로 셋팅이 된다. 따라서 1바이트(1옥텟) 크기의 ASCII와 구분짓기 위해서는 MSB를 무조건 1로 간주해야 하고, 그것도 가로, 세로에 각각 세팅해야 한다. 즉, 1바이트를 읽었을 때 ASCII의 MSB는 0이니 KS X 1001은 1로 놓으면 구분할 수 있다는 것이다. 따라서 KS X 1001의 두 바이트에서 MSB는 1이다. 아래는 두 바이트를 빈칸으로 1바이트씩 구분하여 나타낸 것이다.

1xxxxxxx 1xxxxxxx

그렇다면 128의 제곱인 16,384개를 저장할 수 있겠지만, ASCII에서의 제어문자 33개에 공백(whitespace) 1개를 더한 34개를 각 바이트에 빼준다. 따라서 각 바이트에 94개씩, 총 8,836개의 문자를 저장할 수 있는 것이다. 특히, ASCII로 0000000b부터 0100000b까지는 제어문자(+ 공백)이므로 실질적으로 배정되는 첫 글자의 코드는 10100001b = 0xA1이고, 삭제(DEL)는 1111111b이므로 0xFF도 사용할 수 없으므로 1111110b = 0xFE가 맨 끝에 할당되는 제어문자의 인덱스이다. 즉, [A1][A1]이 첫 글자('가')이고, [FE][FE]가 마지막 글자('힝')이다. 복잡하기만 한 부호 공식은 국내 표준 위원회에서 마음대로 정한 것은 아니고, ISO/IEC 2022 표준(문자 집합을 7비트 부호 또는 8비트 부호로 표현하기 위한 기술)에 의해 정해진 것이다.

(여담이지만, 위 규칙은 1바이트가 8비트인 환경에서의 기준이다. 1바이트가 7비트인 환경에서는 MSB가 1인 점은 무시한다.)

한가지 특이한 점은, 8,836개의 공간에 모두 한글만 저장한 것은 아니다. KS X 1001:2004 정보 교환용 부호계 해설 (1)의 3.2절인 "한글 글자 마디의 선정(1987년 규격을 만들 때의 자료임)" 항목에서는 자주 사용하는 한글 글자를 선정하기 위해 A에서 D까지 네 집단으로 크게 분류하였다. 그리고 해당 집단 내의 각 세부 집단별로 약 1000~2000자씩 조사하여 그 빈도수로 우선순위를 정한 것임을 확인할 수 있다. 이 때, 당시에 조사한 기관이나 언론사 등에서 한자 병용표기를 하였으므로(1987년 신동아 같은 자료를 보면 병행 표기가 자주 있었음을 확인할 수 있다.) 8천자 가량을 모두 한글로 채울 수는 없었을 것이다. 한자와 자주 사용하는 특수문자 등까지 고려해야 했음을 선정된 집단으로 예측할 수 있다는 것이다. 그리고 이 표준은 어디까지나 "산업" 규격이므로 한글을 얼마나 많이 넣는지가 주 목적이 아니라, 실제 산업 현장에서 사용할 법한 글자를 넣는 것이 목적이므로 한자와 특수문자도 고려해야 했을 것이다.

##### 4.2.1.2 EUC-KR과 멀티바이트
정리하자면 상기한 KS X 1001은 표준에 의하면 2바이트의 크기이고, KS X 1003은 사실상 ASCII와 동일하므로 1바이트를 차지한다. KS X 1001을 제정했을 무렵은 ASCII는 이미 대부분의 컴퓨터에서 지원하고 있었을 것이므로 ASCII를 고려한 디자인을 생각할 수 밖에 없었고, 그로인해 두 바이트의 MSB를 각각 1로 셋팅한 것이다. 따라서 KS X 1001과 KS X 1003은 MSB를 보고 구분할 수 있다. EUC-KR이 KS X 1001과 KS X 1003을 혼합하여 사용할 수 있는 이유도 MSB로 구분할 수 있기 때문인데, 서로 다른 바이트를 차지하는 두 규격을 혼합했기에 고정된 크기의 바이트를 차지하는 것이 아닌 문자에 따라 1바이트(주로 영문자, 숫자, 일부 특수문자)와 2바이트(한글, 한자, 1바이트가 아닌 특수문자)로 나뉘게 된다. 이렇게 고정된 공간을 차지하는 것이 아니라 경우에 따라 다른 공간을 차지하는 정도가 다른 글자를 멀티바이트 문자(multi-byte characters)라고 한다. EUC-KR은 멀티바이트 글자를 인코딩하는 방식이라고 할 수 있다.

#### 4.2.2 CP949
KS X 1001이 제공하는 한글 글자의 수는 2350자이다. 엄격한 기준으로 골라낸 글자이지만, 이 표준은 1988년 국립국어원의 국어 개정과 더불어 많은 신조어와 예상치 못한 글자에 대해서 대응하지 못했다. (KS X 1001의 첫 표준은 1987년에 제정되었고, 1992년과 1998년, 2002년을 거쳐 최근 2004년에 개정됨)

엄밀히 말하면 규격 자체는 모든 글자를 표현할 '수'는 있다. KS X 1001-3 (정식 명칭은 KS X 1001 부속서 3) 에서는 보조 부호계라는 항목이 존재하는데, 이 항목은 4.1.3절에서 소개한 2바이트 조합형 부호계이다. 하지만 조합형 자체가 4.1.3절에서 소개했듯이 산업계에서 일관되게 사용하지 않았기 때문에, 그리고 4.1절 마지막 문단에서 소개했듯이 어차피 조합해서 나열해야 알파벳 따위의 외국 글자와 동시에 사용할 수 있기 때문에 조합형을 지원하는 KS X 1001-3(1992년 개정 당시 삼보컴퓨터를 주축으로 하는 '상용조합형'을 표준으로 지정함)을 사용하지 않았다.

앞서 언급했듯이 사실상 KS X 1001에서 제공하는 글자가 2350자이다. 이에 Microsoft에서는 Windows 95를 발매하면서 KS X 1001의 2350자에 현대 국어에서 필요하지만 KS X 1001에는 존재하지 않는 8,822자를 추가하여 확장 완성형(통합 한글 코드, unified hangul code)을 제공했는데, 이 완성형의 코드 페이지(각 글자별로 대응되는 코드가 정의되어 있는 테이블 페이지) 번호가 949번이다. 따라서 CP(Code Page) 949라고 하는 것이다.

![https://upload.wikimedia.org/wikipedia/commons/5/54/Cp949-map.png](https://upload.wikimedia.org/wikipedia/commons/5/54/Cp949-map.png)

CP949 인코딩은 EUC-KR의 확장이다. 따라서 하위 호환성을 만족하기 위해 다음 규칙으로 한글 글자를 배치하였다.

    1. 1바이트가 0x00 이상 0x7F 이하인 경우 : KS X 1003을 할당함
    2. 2바이트가 각각 0xA1 이상 0xFE 이하인 경우 : KS X 1001을 할당함
    3. 나머지 공간에 KS X 1001에 없는 8,822자를 할당

1번과 2번은 EUC-KR과 동일하다. 3번에 대해서는 1, 2번과 충돌하지 않게 할당해 주어야 하는데, 그 상세는 다음과 같다.

    (1) 첫 바이트는 0x81 ~ 0xC6 사이를 할당한다. (각 행의 범위)
    (2) 두 번째 바이트는 0x41 ~ 0x5A, 0x61 ~ 0x7A, 0x81 ~ 0xFE를 할당한다. (위 그림에서 분홍색으로 칠해진 세 조각)
    (3) 첫 번째 바이트가 0xA1 이상인 경우 두 번째 바이트는 0xA1 '미만'으로 할당한다. (KS X 1001과의 충돌을 막기 위함)

#### 4.2.3 기타 완성형
 * KS X 1002
 * 청계천 인코딩

### 4.3 유니코드
![https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Unicode_logo.svg/108px-Unicode_logo.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/a/ab/Unicode_logo.svg/108px-Unicode_logo.svg.png)


1991년 10월 첫 선을 보인 컴퓨팅 산업 표준으로, 전 세계의 모든 문자를 컴퓨터 환경에서 표현하기 위해 만들어진 국제 표준이다. 현재 최신 버전은 2017년 6월에 발표한 10.0 버전이고, 앞으로 계속하여 업데이트를 할 예정이다. (여담으로, 업데이트의 주 목적은 새로운 문자 코드를 추가하기 위함이다.)

앞서 보인 대부분의 한글 처리 인코딩 방식은 한글 코드가 들어있는 코드 페이지(가령, KS X 1001)와 그 페이지를 어떻게 인코딩 할 지(가령, EUC-KR)에 대한 방법이 나뉘어 있는 반면, 유니코드는 문자에 대한 코드 할당 뿐만 아니라 그 인코딩 규칙까지 세부 규칙으로 제시되어 있다. 다만, 흔히 유니코드를 언급할 때는 후술할 UTF-8과 같은 인코딩 규칙인 경우가 많으며, 이번 절의 하위 항목에서도 인코딩 규칙을 중점적으로 다뤄 볼 것이다.

#### 4.3.1 유니코드 관련 개념

 * code point(또는 code position) : code space를 구성하는 임의의 숫자 값을 의미한다. (반대로, code space는 code point가 될 수 있는 값의 범위를 나타낸다.) 대다수의 code point는 하나의 글자를 나타내지만 다른 의미를 갖는 code point도 존재할 수 있다. (가령 문자 서식(formatting)) 이 용어는 유니코드에 한정한 것은 아니고 ASCII나 KS X 1001 등에서도 사용할 수 있다. 특히, 유니코드의 경우 1,114,112 개의 code point를 가지고 있으며, 그 범위(code space)는 0x000000부터 0x10FFFF 사이가 된다.
 * 통상적으로 유니코드에서는 각 code point를 표기할 때 16진수로 표기하되, 접두어로 "U+"를 붙인다. 그리고 16진수가 0xFFF 이하인 경우(즉, 16진수로 세 자리 숫자 이하인 경우) 0을 붙여서 네 자리를 맞춰주는 것이 관례이다. 가령, 알파벳 대문자 'A'인 경우 유니코드로 0x41인데, 이를 유니코드 표기에 맞게 고치면 U+0041이 되는 것이다.
 * Plane : 유니코드의 code point를 65,536(2의 16승)개 씩 묶은 단위이다. (반면, 전체 code space를 일정하게 나눈 범위라고 볼 수도 있다.) code point는 U+0000부터 U+10FFFF 사이의 값을 갖고, 하나의 Plane은 16진수 4자리(2의 16승 = 16의 4승, 16진수 네 자리로 표현됨)에 해당하는 code point를 표현할 수 있다. 따라서, 17개의 Plane(0x00부터 0x10까지)이 일련으로 늘어져 있다고 생각하면서 그 Plane의 번호를 0번부터 매긴다고 생각한다면, U+hhpppp에 해당하는 글자는 0xhh번째 Plane에 0xpppp번째에 배정되어 있는 것과 같다.
 * BMP : 유니코드 협회에서는 많이 쓰일 것 같은 문자나 기호에 대해 앞쪽 Plane에 배정하였다. 특히, 한국을 비롯한 상당수 국가의 글자가 0번 Plane에 배정되어 있다. 따라서 0번 Plane을 BMP(Basic Multilingual Plane)이라고 한다.
 * SMP : 그리고 CJK의 한자를 제외하면서 언어 표기에 보조적으로 필요할 법한 글자는 1번 Plane인 SMP(Supplementary Multilingual Plane)에 배정되어 있다. 옛한글이 바로 SMP에 배정되어 있다. 한편, SIP(Supplementary Ideographic Plane)에서는 앞서 SMP에서 넣지 못한 CJK 표의문자, 그러니까 한자를 넣기 위해 할당된 Plane이다. (한자가 원흉이다.) 특히, 대부분 CJK에서 공통으로 쓰이는 한자(月, 今 등)가 들어가있다.
 * SIP : 3-13번 Plane TIP(Tertiary Ideographic Plane)은 BMP와 SIP에서 배정되지 않은 CJK의 공통 한자 뿐만 아니라 상고한어(유니코드 표준에서는 Old Hanzi Period라고 쓰여있는데, Old Chinese를 말하는 것 같다. 그런데 Old Chinese라고 검색하면 상고한어가 나온다.)까지 포함하는 Plane인데, 한자 갯수가 상당히 많은 관계로 예전에는 이 부분을 아예 배정되지 않음(unassigned)으로 정해놓고 쓰지 않았던 듯 하다. 나무위키의 유니코드 항목에서는 3-13번 Plane을 TIP로 설명한 반면, 영문 위키피디아의 Plane(Unicode) 항목에서는 별도의 명칭 없이 unassigned로만 표기되어 있다.
 * SSP : 14번 Plane에 대해 SSP(Supplementary Special-purpose Plane)이라고 하는데, 태그 문자(tag characters)와 글리프 선택자(glyph selector)를 포함한다. 태그는 ID3v2에서 예를 들면, 아티스트 이름이나 작곡가 등을 서술할 때 일반 유니코드를 사용하지 않고 이 태그 문자를 대신 사용하기 위해 만들어졌다. 위키피디아에서는 "이 태그(U+E0001, 그리고 U+E0020부터 U+E007F)는 원래 보이지 않는 텍스트에 사용할 것을 의도했지만, 더 이상 그 사용을 권장하지 않는다. 여기에 배정된 모든 문자는 유니코드 5.1에서 폐기되었다." 라고 설명하고 있다. 여기서 "보이지 않는 텍스트"라고 함은, 따로 설명하지 않았지만 예상컨데 상기했듯이 ID3v2 같이 바이너리나 사용자가 보이지 않는 곳에 넣는 텍스트를 말하는 것 같다. 한편, 글리프(glyph)는 위키피디아에서 "문맥에 의해 결정될 수 없는 글자에 대해 대체적인 글리프를 지정하기 위한 글리프 변경 선택자(glyph variation selectors)가 포함되어 있다."라고 하는데, 글자가 (오염이 되었든 해서) 문맥상 어떤 글자인지 모를 때 글리프 변경 선택자라는 코드 값이 대체된다는 의미이다. 유니코드 10.0에서 SSP 내부의 code point는 태그(U+E0000부터 U+E007F까지)와 Variation Selectors Supplement(U+E0100부터 U+E01EF까지)를 제외하고 모두 할당되지 않았다.
 *  SPUA-A/B : Supplementary Private Use Area-A(PUA-A), -B(PUA-B)이다. 15번 Plane과 16번 Plane에 대해서는 Private Use Area라고 하는데, 이는 ISO와 유니코드에서 지정한 것 외에 특정 단체나 개인이 가유롭게 문자 코드를 할당하여 사용할 수 있는 영역을 말한다. 폰트가 이 영역을 사용하며, 내부적으로 보조 글리프를 표현하기 위해 사용한다. 가령, 합자(ligatures, "ff"같이 두 개 이상의 글자를 하나의 글리프 안에 넣어 표현하는 것을 의미한다.)를 배정할 수 있다. (당연하겠지만) 이 영역의 코드는 호환성이 떨어질 수 있으며, 유니코드를 지원하는 소프트웨어나 폰트는 반드시 (다른이가) 이 영역에 배정한 글자를 지원할 필요는 없다.

#### 4.3.2 NFC와 NFD
유니코드는 앞서 소개한 한글 인코딩 방식에서 조합형과 완성형 모두를 지원한다. 즉, 모든 자음과 모음을 미리 조합한 글자('가', '나', '다' 등)와 자음과 모음('ㄱ', 'ㅏ', 'ㄴ', 'ㅑ' 등)이 유니코드 내에 동시에 존재하고, 심지어 자음과 모음을 결합하여 글자를 만들 수 있다.('ㄱ', 'ㅏ'에 해당하는 코드를 합쳐 '가'라고 만들 수 있음) 가령 위키백과에 나와있는 예제를 보면, '위'에 해당하는 유니코드는 U+C704이다. 하지만, 'ㅇ'에 해당하는 코드 U+110B와 'ㅟ'에 해당하는 코드 U+1171을 조합하여 나타내도 '위'라고 표현할 수가 있다. 이 때, 후자로 '위'를 표현한 경우(그러니까, 'ㅇ'과 'ㅟ'를 분리하여 표현할 경우) NFD(Nomalization Form D; NF Canonical Decomposition) 방식으로 나타냈다고 하고, 전자로 '위'를 표현한 경우('위' 코드 자체로 표현한 경우) NFC(Nomalization Form C; NF Canonical Composition) 방식으로 나타냈다고 한다.

비슷하게, NFKD(NF Compatibility D)와 NFKC(NF Compatibility C)가 있다. 앞선 NFC와 NFD는 canonical(정준)이 붙기 때문에 정규화 하는 과정(어떤 글자를 NFD 혹은 NFC 형태로 나타내는 과정)에서 그 철자가 반드시 일치해야 한다. 가령, '위'를 분리할 때 'ㅇ'과 'ㅟ'로 정확하게 분리되어야 한다. 하지만 NFKD나 NFKC의 경우 compatibility(호환)이므로 반드시 일치할 필요는 없으며, 의미상 일치하거나 변환할 수 있다고 판단하는 것들로 정규화 할 수 있는 것이다. 예를들어, 'ǆ'라는 글자는 'd'와 'ž'의 분리된 글자가 아니라, 이 둘을 한 쌍으로 묶어서 (따로) 취급한다고 명시되어있다. 하지만, 일부 언어에서 'd'와 'ž'를 결합한 문자로 보기도 하므로 완벽하지는 않지만 'ǆ'를 'd'와 'ž'로 분리할 수도 있다. 그리고 'ž'는 'z'와 caron이 합쳐진 형태이므로 이 둘 또한 분리할 수 있는데, 여기서 분리하여 끝내면('d' + 'z' + caron) NFKD이고, 다시 정준(canonical) 결합하면('d' + 'ž') NFKC이다.

#### 4.3.3 UTF와 UCS
유니코드에서 앞서 설명한 code point를 code value로(일련의 이진 데이터로 나열된 값으로) 대응하는 방법은 두 가지가 있다. 하나가 UTF(Unicode Transformation Format) 인코딩이고, 다른 하나는 UCS(Universal Coded Character Set) 인코딩이다. UTF 인코딩 방식도 세부적인 방법으로 나뉘는데, 모든 UTF 인코딩은 [surrogates](https://en.wikipedia.org/wiki/Universal_Character_Set_characters#Surrogates)를 제외한 모든 code point를 유일한 바이트 열로 대응시킨다. 인코딩 이름에 적혀있는 숫가가 code value당 차지하는 비트(UTF 인코딩 방식의 경우)이거나 바이트(UCS 인코딩 방식의 경우)이다. UTF-8과 UTF-16이 흔히 사용하는 인코딩 방식이다.

##### 4.3.3.1 UTF-8
![https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Utf8webgrowth.svg/700px-Utf8webgrowth.svg.png](https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Utf8webgrowth.svg/700px-Utf8webgrowth.svg.png)

2000년 중후반 이후 전세계에서 가장 많이 쓰이는 유니코드 인코딩 방식이다. 앞서 UTF 인코딩 방식에서 이름에 붙인 숫자가 code value당 차지하는 비트라고 언급했는데, UTF-8의 경우 반은 맞고, 반은 틀린 것이다. 이 이름 짓는 규칙에 의하면 UTF-8은 8비트를 차지하는 code value로 인코딩 해 주어야 한다. 그러나, UTF-8은 실제로는 최대 21bit의 code value를 수용할 수 있는 가변 길이 인코딩 방식이다. 다만, code point의 범위를 세운 다음 각 범위에 따라 1바이트씩 증가하여 인코딩을 하기 때문에 8이라는 숫자가 아주 무의미하지는 않다. (여담이지만, 이름을 UTF-8x로 하는건 어떨까 생각해본다.)

UTF-8 인코딩 방식은 상기한대로 code point별로 범위를 나누어 code value를 표현했는데, 그 상세는 다음과 같다.

(아래 표에서 바이트 열 항목은 1바이트씩 끊어서 표기했음)

|바이트 수|code point별 비트 수|code point 하한|code point 상한|바이트 열|
|---|---|---|---|---|
| 1 | 7 | U+0000|  U+007F|0xxxxxxx|
| 2 | 11| U+0080|  U+07FF|110xxxxx 10xxxxxx|
| 3 | 16| U+0800|  U+FFFF|1110xxxx 10xxxxxx 10xxxxxx|
| 4 | 21|U+10000|U+10FFFF|11110xxx 10xxxxxx 10xxxxxx 10xxxxxx|

일단, 1바이트를 차지하는 경우는 ASCII(3.1절)와 호환하기 위해 지정한 구역이다. 총 7비트를 사용하되, MSB가 0인 점으로 나머지 2~4바이트와 구분된다. 그리고 2바이트부터는 첫 바이트의 MSB와 그 하위비트에 1이 붙으며, 첫 바이트에 꼬리를 무는 바이트는 모두 "10"으로 구분하였다. 즉, 첫 바이트를 읽어 MSB로 ASCII와 ASCII가 아닌 것으로 구분하며, 첫 바이트의 MSB 하위 비트를 읽어 ASCII가 아닌 경우(2~4바이트를 사용하는 경우) 꼬리를 무는 바이트가 얼마나 되는지 구분한다. "110"과 "1110"과 "11110"이 모두 서로를 구분짓기 위함(심지어 "10"과도 구분짓기 위함)이다. 그외의 x라고 표기된 자리는 code point 값을 그대로 비트로 넣는다.

CJK를 UTF-8로 인코딩할 때, 대부분 3바이트 영역에서 인코딩된다. 따라서 세간에는 EUC-KR에서 "영문, 숫자=1바이트 & 한글=2바이트" 공식으로 알려졌듯이, UTF-8은 3바이트로 알고 있는 경우가 많다. 한글만 쓰는 문서에서는 틀리지 않았지만 UTF-8을 설명하기에는 많이 모자르다.

##### 4.2.3.2 UTF-16
UTF-16 방식은 BMP를 16비트로 표현할 수 있는 가변길이 인코딩 방식이다. BMP는 16비트로 표현할 수 있으므로 그냥 표현하되, BMP를 제외한 나머지 Plane에 속해있는 code point에 대해서는 다음 규칙으로 표기한다.

 1. code point에서 0x10000을 뺀다.
 2. 그 값을 둘로 쪼개면 10비트 두 개로 나타낼 수 있다.
 3. 앞 10비트에 대해 앞에 110110b를 붙여 16비트로 만든다.
 4. 뒤 10비트에 대해 앞에 110111b를 붙여 16비트로 만든다.

1번이 가능한 이유는, BMP를 제외한 나머지 Plane에 대한 규칙이기 때문이다. BMP는 첫 번째 Plane이므로 U+0000부터 U+FFFF까지의 code point를 갖는다. 그 이후의 Plane은 무조건 U+10000 이상이기 때문에 BMP가 없다고 가정하면 U+0000부터 사용할 수 있다. 따라서 0x10000을 빼는 것이다.

2번이 가능한 이유는, BMP를 제외한 Plane은 구간 길이가 1,048,576(2의 20승)이기 때문이다. U+10000과 U+10FFFF 구간의 길이와 같은데, 이 사이의 모든 code point는 20비트 길이의 값으로 나타낼 수 있다. 이를 쪼개면 10비트 두 개가 나오는 것은 자명하다. (10비트가 되지 않는 값은 상위 비트를 모두 0으로 채우면 된다.)

3번과 4번에 대해서는 일부러 16비트를 만들어주기 위한 것도 있지만, BMP 이외의 Plane의 code point라고 알려주는 역할도 한다. UTF-8에서 바이트 구분을 위해 1을 여러 번 붙인 것과 그 원리가 같다. 이렇게 일부러 6비트를 각 10비트에 붙이면 마치 BMP처럼 16비트로 취급할 수 있으나, 우연히 BMP의 이 부분에 할당한 문자와 값이 같으면 충돌할 수가 있다. 특히, BMP에 "110110xx xxxxxxxx"와 "110111xx xxxxxxxx" 패턴의 값이 존재한다면 무조건 충돌하게 되어있다. 이를 고려하여, BMP의 U+D800~U+DBFF 구간과 U+DC00~U+DFFF 구간은 UTF-16을 위해 비워두었다. (이 영역을 surrogates라고 한다.)

앞서 2번에서 10비트 두 개로 쪼갤 때, 앞 10비트를 high surrogate, 뒤 10비트를 low surrogate라고 한다.

##### 4.2.3.3 UTF-32
32비트의 고정된 길이를 갖는 인코딩 방식이다. 모든 code point를 32비트로 표현하다보니 상당한 비트(leading bits)가 0으로 채워질 뿐만 아니라, 유니코드의 모든 code point는 21비트로 표현할 수 있어서 나머지 11비트는 항상 0으로 채워진다. 대부분의 문자가 BMP에 존재하기 때문에 BMP로만 이루어진 텍스트의 경우 16비트가 낭비인 셈이다. 한 술 더 떠서, 만일 라틴 문자와 숫자 정도로만 이루어진 텍스트라면 무려 24비트를 의미없이 0으로 채우는 꼴이기 때문에 잘 사용되지는 않는다.

UTF-32의 장점은 (매우 크고 아름다운 비트를 차지하기 때문에) 존재하는 모든 유니코드의 code point에 그대로 대응할 수 있다는 점이다. 가변길이가 아니라 고정길이이기 때문에, 그리고 0부터 차례대로 대응시키면 되기 때문에 아주 직관적이고 UTF-8이나 UTF-16처럼 비트를 쪼개는 등의 복잡한 연산이 필요 없다.

UTF-32는 흔히 UCS-4와 혼용하기도 하는데, 이는 UTF-32가 탄생한 배경이 UCS와 관련이 있기 때문이다. UCS는 0부터 0x7FFFFFFF(MSB는 사용하지 않고 항상 0으로 채워짐)까지 다양한 값을 가질 수 있는, 유니코드와 바슷한 문자 집합이다. 이 값을 채우기 위해서는 32비트의 공간이 필요하다. 한편, 2003년 11월에 공표된 RFC3629는 UTF-16 인코딩 방식의 제약사항과 맞추기 위해, 유니코드는 U+10FFFF보다 큰 code point를 가질 수 없다고 명시적으로 금지하였다. 이 때, UTF-16 방식에서 제약사항은 다음과 같다.

 * BMP를 제외한 나머지 구간을 표시할 때 20비트로 표현했는데, 다르게 말하면 이 구간의 크기를 20비트를 넘기면 안된다는 것이다.
 * UTF-16 표기를 위해 BMP의 U+D800~U+DBFF, U+DC00~U+DFFF까지는 사용하지 말아야 한다.

특히, 첫 번째 이유가 유니코든느 U+10FFFF까지의 code point를 가져야 한다는 제약사항의 결정적인 근거가 된다. 어쨌든, 앞서 UCS의 code point 길이가 32비트인 점과 유니코드의 code point를 제한하고 사용하지 못한다는 점이 UTF-32를 새로 정의하게 된 계기가 되었다.

과거 1998년 유니코드 버전 2.1에서 0xE00000~0xFFFFFF까지, 그리고 0x60000000~0x7FFFFFFF까지를 "개인적인 사용을 위해 예약됨(reserved for private use)"라고 표준화 하기는 했지만, 이후 버전에서 이 구간에 대한 명시가 제거되었다. 한편, "ISO/IEC JTC 1/SC 2/WG 2의 원칙과 절차(Principles and Procedures document of ISO/IEC JTC 1/SC 2 Working Group 2)"에 대한 문서에는 향후 (UCS의) 모든 code point의 배정은 유니코드 범위로 제한할 것이라고 명시했기 때문에 UTF-32는 모든 UCS의 code point를 나타낼 수 있을 것이고, 실제로 UTF-32와 UCS-4는 동일하다.

##### 4.3.3.4 UCS-2
UCS-2는 UTF-16의 이전 버전이자 부분집합이다. 2바이트로 code value를 나타내며, 정확히 유니코드의 BMP를 표현할 수 있는 공간이다. 실제로, BMP 외의 Plane에 속한 code point는 표현할 수 없다. UTF-16은 UCS-2에서 확장하여 BMP 이외의 Plane에 속한 code point도 표현할 수 있도록 하였다.

##### 4.3.3.5 UCS-4
UTF-32와 마찬가지로 고정 32비트 인코딩 방식이다. 따라서, 각 문자에 대해 0부터 (이론적으로) 0x7FFFFFFF사이의 단일 code value를 사용한다. UCS-4는 BMP 외에도 UCS의 모든 code point에 대해 이진 데이터로 표현할 수 있다.

## 5. Win32에서 한글 인코딩

### 5.1 C++ 표준 문자열 처리
전통적으로 C++는 C를 닮아 문자열(string)이 기본 자료형으로 존재하지 않았고, 문자를 일렬로 늘어놓는 모양으로 생각했다. 그렇다면, 문자를 자료형으로 표현할 때 그 자료형을 일정 길이로 연속된 공간에 들어가는 것이고, 이는 배열의 정의와 맞아 떨어지게 된다. 이 때, C++의 배열은 길이를 따로 보관하지 않으므로 배열(문자열)의 끝을 알리는 문자를 따로 넣어줘야 하는데, 그 문자가 NULL이다. 이 떄문에, C나 C++ 에서는 문자열을 널 종료 문자열(null terminated string)이라고 말하기도 한다.

C나 C++에서는 문자열을 기본으로 제공하지 않기 때문에 문자열과 관련된 연산을 수행하는 함수를 라이브러리 차원에서 제공하고 있다. string.h(C++에서는 cstring)이 대표적인데, 문자열의 길이를 계산하는 strlen(C++은 std::strlen), 문자열을 다른 메모리 공간에 복사해주는 strcpy(C++은 std::strcpy) 등이 있다. 하지만 C나 C++에서 문자열 처리를 어렵게 하는 근본적인 이유는 바로 '문자'에 대한 정의가 모호하기 때문이다. 앞선 문단에서 C/C++의 문자열이라 함은 일련의 문자 배열로 생각한다고 했는데, 정의 자체는 이상할 것이 없으나 문제는 '문자'를 어디에 맞출 것인지 언어 표준에서 정해주지 않았다는 것이다. (정확히 말하면 유니코드 절에서 언급한 code value를 어디를 기준으로 하는지 결정해주지 않았다는 것이다.) 따라서 같은 문자열임에도 시스템에 따라 간주하는 문자 셋이나 인코딩 방식이 다를 수 있어 온전히 문자열을 보관하고 전달하기 힘들다.

한편, `wchar_t` 자료형이 C++에 도입되었는데, 이 자료형 역시 어떤 문자의 code point도 표현할 수 있도록 충분히 큰 값을 제공하도록 명시하고 있다. 특히, 유니코드를 지원하는 시스템에서는 `wchar_t`는 32비트를 차지한다고 했는데, Windows는 예외로 16비트를 차지하면서 UITF-16의 코드 단위(code units)를 보관할 수 있다고 한다. UTF-16 방식의 경우 BMP 외의 Plane에 대해서 16비트 두 개로 표현하기 때문에 `wchar_t` 변수 하나가 문자 하나와 반드시 대응되는 것은 아니다. 그리고 여담으로, `char`형 문자열을 null-terminated string이라고 했듯이, `wchar_t`형 문자열을 null-terminated wide string이라고 한다.

`char`과 `wchar_t` 자료형이 이렇게 모호한 이유는 언어 차원에서 문자 인코딩 방식을 강제하지 않았기 때문이며, C++ 14에서 UTF-8 코드 단위를 보관할 수 있을정도로 충분히 크다고 했지만, VS에서는 두 자료형에 대해 각각 1바이트와 2바이트로 고정해 놓았다. 그리고 g++ 컴파일러에서는 C++ 14버전으로 빌드해도 UTF-8로 지정한 문자열(접두어 u8을 사용하는 문자열)에 대해 `char` 타입이 1바이트씩 차지함을 확인하였다. (UTF-8에서 한글의 code value가 3바이트씩 차지하기 때문에 한 글자에 배열 길이를 3씩 잡아 먹었으며, "안녕하세요" 라는 문자열에 대해 길이를 16이라고 출력하였다. 5글자 곱하기 3 + null = 16)

기타로, C++ 11에서 새롭게 도입된 `char16_t`와 `char32_t` 자료형은 각각 UTF-16과 UTF-32를 나타내기 위한 고정 크기의 자료형으로, `char16_t`는 `std::uint_least16_t`와, 그리고 `char32_t`는 `std::uint_least32_t`와 동일한 크기, 부호성(signedness), 정렬(alignment) 성질을 갖음에도 서로 다른 타입으로 간주한다.

### 5.2 Win32의 문자열 처리
마이크로소프트는 Windows 95를 출시하면서 유니코드와는 별개의 노선으로 CP949를 내놓는다. (4.2.2절) 이 부분에 대해서는 4.2.2절에 말했지만, 유니코드 이전의 한글 처리 방식인 KS X 1001과 KS X 1003을 반영하면서 독자적으로 다른 한글도 추가한 문자 셋이자 인코딩 방식이다. (KS X 1003은 엄밀히 말하면, 한글 처리 방식이라기 보다는 역슬래시를 원화 기호로 바꾼 ASCII의 아류쯤 되는 표준이다.) 이 방식은 Windows 95, 98, ME(Millennium Edition)에서 기본으로 사용하던 인코딩 방식이다. 반면, Windows NT계열은 Windows NT 4.0 이전부터 유니코드를 제공하기 시작했고, 그 중에서도 UTF-16을 채택하고 있다. 따라서, 앞으로 윈도우 기반의 응용 프로그램 개발은 유니코드를 지원해야 하며, 이는 현재 추세와 비슷하다.

한편, Win32 Application을 개발하기 위한 라이브러리 중에는 MFC(Microsoft Foundation Classes)가 있는데, MFC는 MBCS(Multi-Byte Character Set)라는 개념이 존재한다. 다국어를 지원하기 위해 여러 나라의 문자 인코딩을 2바이트 내에서 표현하도록 통일한 것인데, 한국어에서 MBCS는 곧 CP949를 의미하기도 하다. CP949가 1바이트(KS X 1003) 혹은 2바이트(KS X 1001 + a)로 나타내고 MBCS는 한국어 페이지에서는 CP949를 따른다. 이 때문에 저장된 문자와 그 문자를 나타내는 바이트가 일 대 일로 매치가 되지 않고, 문자 혹은 문자열을 편집할 때 유의해야 한다. 즉, 값의 범위를 따져 한 바이트를 조작할 것인지 두 바이트를 조작할 것인지 결정해야 한다.

Windows 9x 기반에서는 CP949가 한글의 기본 처리 방법이고, MBCS도 이를 따르므로 큰 문제는 없어보였으나, Windows NT 기반에서는 유니코드를 정식으로 제공하면서 MBCS와 유니코드간의 이식성 문제가 발생하게 된다. 특히 Win32 응용 프로그램을 빌드할 때 발생하는데, 이를 해결하기 위해 MS는 전처리 기호로 이 둘을 구분한다. 유니코드 방식으로 빌드할 경우 `_UNICODE`를 `#define`으로 선언하고 MBCS로 빌드할 경우 `_MBCS`를 선언해야 한다. 만일 두 개가 모두 정의되어 있지 않은 경우는 SBCS(Single-Byte Character Set, ASCII)로 빌드한다고 하며, 두 개가 모두 선언되어 있는 경우는 동작을 보장하지 않는다고 한다.

그리고 `_UNICODE`로 선언할 때, 문자 하나를 제어하는 자료형인 `_TCHAR`는 `wchar_t`로 정의된다. 반면, `_MBCS`인 경우 `_TCHAR`는 `char`로 정의된다. 이 때, MBCS와 유니코드 모두 1바이트 혹은 2바이트씩 접근하면 안되고 반드시 한 글자씩 접근해야 한다. 이를 `_TCHAR` 단위로 작동한다고 표현하며, `_TCHAR` 단위로 문자열을 조작하기 위해 `_tcs` 함수를 사용해야 한다.

### 5.3 `char` vs `_TCHAR`
Windows 환경에서는 상기했듯이 유니코드나 MBCS에 대해 유연하게 대처해야 하므로 `_TCHAR`를 사용하는 것이 유리하다. `char`는 MBCS를 처리하기에는 유리하지만 유니코드는 처리할 수 없으며, `wchar_t`는 그 반대이다. 따라서, 시스템에 따라 달라지는 타입에 대해서는 메크로(중간) 타입을 두어 적절하게 재정의 하는 것이 낫다.

하지만 `_TCHAR` 타입은 C++ 표준은 아니므로 Win32 외에서는 사용할 수 없거나, 다른 환경에서 사용하기 위해서는 `_TCHAR` 타입을 직접 정의해 주어야 한다. 하지만, `_TCHAR` 타입은 단순히 자료형을 정의하는 것에서 그치는 것이 아니라 자료형에 따라 오는 문자열 연산을 포함하는데, 이 연산(함수)을 사용하기 위해서는 결국 Win32에 종속적이게 된다.

뿐만 아니라, C++에서 문자 타입은 시스템에서 가장 효율적으로 나타낼 수 있는 문자를 담을 수 있는 것으로 정의되어 있다. 이는 매우 모호한 내용이라 꼭 `_TCHAR`가 아니더라도 `char`나 `wchar_t`를 사용할 때도 해당 시스템이 어떤 인코딩 방식을 사용하여 (바이트 열을) 조작해야 할지 고민해 보아야 할 것이다.

## 6. 참고자료
 * [KS X 1001:2004, 한국정보통신기술협회](https://standard.go.kr/KSCI/standardIntro/getStandardSearchView.do?ksNo=KSX1001&reformNo=05)
 * [KS X 1001, 위키백과](https://ko.wikipedia.org/wiki/KS_X_1001)
 * [KS X 1001, 리브레 위키](https://librewiki.net/wiki/KS_X_1001)
 * [코드 페이지 949, 위키백과](https://ko.wikipedia.org/wiki/%EC%BD%94%EB%93%9C_%ED%8E%98%EC%9D%B4%EC%A7%80_949)
 * [완성형, 나무위키](https://namu.wiki/w/%EC%99%84%EC%84%B1%ED%98%95)
 * [CP949, 나무위키](https://namu.wiki/w/CP949)
 * [Unicode, Wikipedia](https://en.wikipedia.org/wiki/Unicode)
 * [Unicode codespace, unicode.org](http://unicode.org/glossary/#codespace)
 * [Unicode 10.0.1 Roadmap, unicode.org](https://www.unicode.org/roadmaps/tip/tip-10-0-1.html)
 * [Tags(Unicode block), Wikipedia](https://en.wikipedia.org/wiki/Tags_(Unicode_block))
 * [유니코드 정규화, 위키백과](https://ko.wikipedia.org/wiki/%EC%9C%A0%EB%8B%88%EC%BD%94%EB%93%9C_%EC%A0%95%EA%B7%9C%ED%99%94)
 * [Unicode qeuivalence Normalization, Wikipedia](https://en.wikipedia.org/wiki/Unicode_equivalence#Normalization)
 * [Dž, Wikipedia](https://en.wikipedia.org/wiki/D%C5%BE)
 * [NFC ~ NFKD sections, unicode.org](https://unicode.org/glossary/#normalization_form_c)
 * [Unicode UTF, Wikipedia](https://en.wikipedia.org/wiki/Unicode#UTF)
 * [UTF-8, Wikipedia](https://en.wikipedia.org/wiki/UTF-8)
 * [UTF-32, Wikipedia](https://en.wikipedia.org/wiki/UTF-32)
 * [Universal Coded Character Set, Wikipedia](https://en.wikipedia.org/wiki/Universal_Coded_Character_Set)
 * [ISO/IEC JTC 1/SC 2, Wikipedia](https://en.wikipedia.org/wiki/ISO/IEC_JTC_1/SC_2)
 * [기본 형식 (C++), MSDN](https://msdn.microsoft.com/ko-kr/library/cc953fe1.aspx)
 * [MBCS(멀티바이트 문자 집합) 지원, MSDN](https://docs.microsoft.com/ko-kr/cpp/text/support-for-multibyte-character-sets-mbcss)
 * [Tchar.h의 제네릭 텍스트 매핑, MSDN](https://msdn.microsoft.com/ko-kr/library/c426s321.aspx)
 * [char, wchar_t, char16_t, char32_t](https://msdn.microsoft.com/ko-kr/library/mt228149.aspx)
 * [Character types, cppreference](http://en.cppreference.com/w/cpp/language/types)